# 7.MobileNet V1 V2

2017年Google团队提出MobileNetV1，2018年Google团队提出MobileNetV2，论文地址[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/pdf/1704.04861.pdf), [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/pdf/1801.04381.pdf)

专注于移动端或嵌入式设备中的轻量级CNN网络，相比于传统CNN，在准确率小幅度降低的前提下大大减小模型参数与运算量。（相比VGG16准确率减少了0.9%，模型参数只有1/32）。

**MobileNetV1:**

网络的亮点：深度可分离卷积（Depthwise Separable Convolution）

<img src="D:\CSDN\CNN\figures\图24 传统卷积.png" style="zoom:67%;" />

<center>
    图24 传统卷积
</center>

卷积核channel=输入特征矩阵channel
输出特征矩阵channel=卷积核个数

<img src="D:\CSDN\CNN\figures\图25 DW卷积.png" style="zoom:67%;" />

<center>
    图25 DW卷积
</center>

卷积核channel=1
输入特征矩阵channel=卷积核个数=输出特征矩阵channel

每个卷积核只负责与输入中的一个channel进行运算

<img src="D:\CSDN\CNN\figures\图26 PW卷积.png" style="zoom:67%;" />

<center>
    图26 PW卷积
</center>

![](D:\CSDN\CNN\figures\图27 卷积参数对比.png)

<center>
    图27 卷积参数对比
</center>

在训练过程中，Depthwise部分的卷积核容易废掉，即卷积核参数大部分为0，在MobileNetV2中会进行改善。

**MobileNetV2：**

网络的亮点：

Inverted Residuals倒残差结构
Linear Bottleneck

<img src="D:\CSDN\CNN\figures\图28 Inverted residual.png"  />

<center>
    图28 倒残差结构
</center>

普通残差结构：1×1conv降维，3×3conv，1×1conv升维
倒残差结构：1×1conv升维，3×3DW，1×1PW降维

针对倒残差结构的最后一个1×1卷积层，使用线性激活函数而不是ReLU，因为ReLU激活函数对低维特征信息造成大量损失，而倒残差结构中间大两边小，最后一个1×1卷积后是低维的，则使用线性激活函数来替代ReLU，来避免信息损失。

<img src="D:\CSDN\CNN\figures\图29 Bottleneck residual.png" style="zoom:50%;" />

<center>
    图29 Bottleneck residual block
</center>

<img src="D:\CSDN\CNN\figures\图30 MobileNetV2.png" style="zoom:67%;" />

<center>
    图30 MobileNetV2网络结构
</center>

其中，t是图29中的扩展因子，c是输出特征矩阵深度，n为bottleneck重复次数，s为步距（针对第一层，其他为1）

[pytorch实现](https://github.com/gdww97/CNN/blob/master/codes/MobileNet.py)

在pytorch实现时，在bottleneck的conv运算中，加入了groups，分解卷积。