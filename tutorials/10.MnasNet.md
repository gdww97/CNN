# 10.MnasNet

2019年由Google大脑团队提出，论文地址：[MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://arxiv.org/pdf/1807.11626.pdf)

比MobileNet精度和实时性更高的模型，用强化学习搜索出来的深度卷积神经网络，主要优化目标有两个，识别准确率和CPU运算延迟。

![](D:\CSDN\CNN\figures\图36 搜索结构.png)

<center>
    图36 神经架构搜索
</center>

其中，模型只在ImageNet上简单跑“5个epochs”，然后转换成TFLite，再在Pixel 1上用单CPU核测试“延迟”。所以搜索出来的8K个模型，大多数也还是没在ImageNet上完整训练过，只有最好的<15个模型，进行了完整的ImageNet或COCO的训练。

![](D:\CSDN\CNN\figures\图37 MnasNet.png)

<center>
    图37 MnasNet
</center>

搜索得到基线结果MnasNet中的五种层的结构，有两种分别于MobileNet V1 V2中的层相同，证明了人工设计的确实优秀。

[pytorch实现](https://github.com/gdww97/CNN/blob/master/codes/MnasNet.py)

借助了倒残差结构，没有用SE模块。